{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Insufficient Data (2D Range-only)\n",
    "\n",
    "**API Version: Python NavAbilitySDK.py**\n",
    "\n",
    "**Keywords:** Range-only, factor graph, under-determined, localization, mapping, SLAM, missing data, insufficient data, robotics, inference, Bayes tree, junction tree\n",
    "\n",
    "## Overview\n",
    "\n",
    "This example shows how non-Gaussian solutions occur from weak observability of desired variables from available data.  For this tutorial, we imagine a robot traveling around on a flat surface, in a rectangular trajectory making range measurements to beacons.  Let's assume WiFi power levels are used as a proxy for range measurements in this case.\n",
    "\n",
    "<img src=\"https://github.com/NavAbility/BinderNotebooks/raw/main/static/icra-3/example-wifi.png\" width=800>\n",
    "\n",
    "To illustrate the the underdetermined solution aspect, we simplify the problem in that WiFi ranging is assumed to produce a pure unimodal (Gaussian) measurement.  This tutorial will show how non-Gaussian behavior can arise because tha variables are weakly or underconstrained by the available measurement dimensions.  This tutorial is designed such that this occurs throughout the entire problem.\n",
    "\n",
    "We build a factor graph in stages as the robot moves around the environment through pose/keyframe epochs.  The factor graph will be solved with the [open core Caesar.jl solver](https://github.com/JuliaRobotics/Caesar.jl) at each pose epoch, which produces the posterior marginal beliefs on each of the variables in the system.  After each pose epoch solution, we will look at the marginal belief estimates of all the variables in the system.\n",
    "\n",
    "We assume the robot is traveling on a XY plane, starting at the origin along X and turning left along Y, then negative X, negative Y back to the origin.  Only four WiFi beacons are in the environment where the robot is moving.  Measurements to the WiFi beacons can only be included with there if the signal is within range.  Two of the beacon locations are known as prior information, while the other two beacons are at an unknown location and their location will be eastimated simultaneously to the robot pose location in the same factor graph system -- making this a simultaneous localization and mapping (SLAM) problem.\n",
    "\n",
    "To further simplify the tutorial, the \"odometry\" measurement between consecutive poses  are also taken as range-only (i.e. distance-only) measurements.  These \"odometry\" factors provide less information than conventional wheel or visual odometry constraints might provide.\n",
    "\n",
    "This tutorial shows [one of four mechanisms](https://juliarobotics.org/Caesar.jl/latest/concepts/why_nongaussian/) that can intoduce non-Gaussian behavior into a factor graph system, see other examples for other mechanisms.  Note that the techniques used in this tutorial can readily be combined with with methods from other tutorials.  For example, the pure Gaussian measurement ranging models used here can be replaced with ambiguous measurements shown in ICRA Tutorial 2.  Or, can be combined with uncertain data association (i,e. multi-hypothesis) measurement models for unknown beacon associations similat to the technique used in ICRA Tutorial 4.  Learn more from our peer-reviewed publications listed here: `CJLDocs/Literature`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signatures Used\n",
    "\n",
    "`Point2`, `PriorPoint2`, `Point2Point2Range`, `MvNormal`, `Normal`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Data\n",
    "\n",
    "The ground truth positions for vehicle positions GTp and landmark positions GTl can be loaded into memory directly with these values.  **Note,** we are using variable names\n",
    "- `l1, l2` as ranging beacons with known locations,\n",
    "- `l3, l4` as ranging beacons with initially unknown locations,  \n",
    "\n",
    "These beacon landmarks must be in range before measurements can be made to them.  For the tutorial, we imagine a robot moving from one position to the next in the XY space between the landmarks.  We use ground truth positions to build the simulation, while the SLAM solution has to resolve estimates of the variables as the main exercise of the tutorial.  The robot positions are denoted as\n",
    "- `x0, x1, ...`.\n",
    "\n",
    "Ground truth data is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Our dictionary of vehicle positions\n",
    "GTp = {}\n",
    "GTp[\"x0\"] = np.array([0.0, 0])\n",
    "GTp[\"x1\"] = np.array([50.0, 0])\n",
    "GTp[\"x2\"] = np.array([100.0, 0])\n",
    "GTp[\"x3\"] = np.array([100.0, 50.0])\n",
    "GTp[\"x4\"] = np.array([100.0, 100.0])\n",
    "GTp[\"x5\"] = np.array([50.0, 100.0])\n",
    "GTp[\"x6\"] = np.array([0.0, 100.0])\n",
    "GTp[\"x7\"] = np.array([0.0, 50.0])\n",
    "GTp[\"x8\"] = np.array([0.0, -50.0])\n",
    "\n",
    "# Our dictionary of landmark positions\n",
    "GTl = {}\n",
    "GTl[\"l1\"] = np.array([10.0, 30])\n",
    "GTl[\"l2\"] = np.array([30.0, -30])\n",
    "GTl[\"l3\"] = np.array([80.0, 40])\n",
    "GTl[\"l4\"] = np.array([120.0, -50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Necessary Packages\n",
    "\n",
    "Next, lets load the required Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from navability.entities import *\n",
    "from navability.services import *\n",
    "from uuid import uuid4\n",
    "import asyncio\n",
    "from numpy.linalg import norm\n",
    "# use markdown to link to graph and map visualizations\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "# Helper functions for NavAbility App visualizations\n",
    "def GraphVizApp(client):\n",
    "  topography_vis_link = f\"https://app.navability.io/cloud/graph?userId={client.userId}&robotStartsWith={client.robotId}&sessionStartsWith={client.sessionId}\"\n",
    "  print(topography_vis_link)\n",
    "  try:\n",
    "    return md(f\"\"\"[![Navigate to Factor Graph](http://www.navability.io/wp-content/uploads/2022/03/factor_graph.png)]({topography_vis_link})\"\"\")\n",
    "  except:\n",
    "    return\n",
    "\n",
    "def MapVizApp(client):\n",
    "  geometry_vis_link = f\"https://app.navability.io/cloud/map?userId={client.userId}&robotStartsWith={client.robotId}&sessionStartsWith={client.sessionId}\"\n",
    "  print(geometry_vis_link)\n",
    "  try:\n",
    "    return md(f\"\"\"[![Navigate to Factor Graph](http://www.navability.io/wp-content/uploads/2022/03/geometric_map.png)]({geometry_vis_link})\"\"\")\n",
    "  except:\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Factor Graph\n",
    "\n",
    "After loading the requried packages, lets start creating the factor graph using variables of type `Point2` (a.k.a. `Postion2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with an empty factor graph\n",
    "navability_client = NavAbilityHttpsClient()\n",
    "client = Client(\"Guest\", \"SDKpy_\" + str(uuid4())[0:4], \"Tutorial3_\" + str(uuid4())[0:4])\n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an initial position x0 for the robot, and three landmarks l1, l2, and l3 to \n",
    "# indicate the position of the Wifi routers (beacons) \n",
    "variable_ids = [\"x0\", \"l1\", \"l2\", \"l3\"]\n",
    "\n",
    "# Add the variables\n",
    "result_ids = []\n",
    "for v_id in variable_ids:\n",
    "    v = Variable(v_id, VariableType.Point2.value)\n",
    "    result_ids.append(await addVariable(navability_client, client, v))\n",
    "\n",
    "# Wait for all the variables to be loaded.\n",
    "await waitForCompletion(navability_client, result_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial graph also has prior location information about each of the known beacons/landmarks `:l1` and `:l2`.  Let's go ahead and add those as factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and put priors on l1 and l1, centered at l1 and l2 respectively with covariance of 1 \n",
    "result_ids = []\n",
    "for prior_landmark_id in [\"l1\", \"l2\"]:\n",
    "  prior_distribution = FullNormal(mu=GTl[prior_landmark_id], cov=np.diag([1, 1]))\n",
    "  prior_factor = Factor(f\"{prior_landmark_id}f1\", \"PriorPoint2\", [prior_landmark_id], FactorData(fnc=PriorPose2(Z=prior_distribution).dump()))\n",
    "  result_ids.append(await addFactor(navability_client, client, prior_factor)) \n",
    "\n",
    "# Wait for it to be loaded.\n",
    "await waitForCompletion(navability_client, result_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PriorPoint2` is assumed to be a multivariate normal distribution of covariance `diagm(ones(2))`. Note the API `PriorPoint2(::SamplableBelief)` accepts any of the distribution objects that the Caesar.jl libraries support -- this is discussed further in subsection [Various `SamplableBelief` Distribution types](https://juliarobotics.org/Caesar.jl/latest/concepts/dataassociation/#Various-SamplableBelief-Distribution-Types)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Range Measurements Between Variables\n",
    "\n",
    "Next we connect the three range measurements from the vehicle location `:l0` to the three beacons, respectively – and consider that the range measurements are completely relative between the vehicle and beacon position estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = []\n",
    "# first range measurement from x0 to l1\n",
    "rhoZ1 = norm(GTl[\"l1\"]-GTp[\"x0\"])\n",
    "ppr = Point2Point2Range(Z=Normal(rhoZ1, 2))\n",
    "range_factor = Factor(f\"x0l1f1\", \"Point2Point2Range\", [\"x0\", \"l1\"], FactorData(fnc=ppr.dump()))\n",
    "factors.append(range_factor)\n",
    "\n",
    "# second range measurement from x0 to l2\n",
    "rhoZ2 = norm(GTl[\"l2\"]-GTp[\"x0\"])\n",
    "ppr = Point2Point2Range(Z=Normal(rhoZ2, 2))\n",
    "range_factor = Factor(f\"x0l2f1\", \"Point2Point2Range\", [\"x0\", \"l2\"], FactorData(fnc=ppr.dump()))\n",
    "factors.append(range_factor)\n",
    "\n",
    "# third range measurement from x0 to l3\n",
    "rhoZ3 = norm(GTl[\"l3\"]-GTp[\"x0\"])\n",
    "ppr = Point2Point2Range(Z=Normal(rhoZ3, 2))\n",
    "range_factor = Factor(f\"x0l3f1\", \"Point2Point2Range\", [\"x0\", \"l3\"], FactorData(fnc=ppr.dump()))\n",
    "factors.append(range_factor)\n",
    "\n",
    "# Add all of them\n",
    "result_ids = [(await addFactor(navability_client, client, f)) for f in factors]\n",
    "# Wait for it to be loaded.\n",
    "await waitForCompletion(navability_client, result_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranging measurement standard deviation of 2.0 or 3.0 is taken, assuming a Gaussian measurement assumption. Again, any distribution could have been used. The factor graph should look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a clickable button link to see you specific session via the NavAbility App.\n",
    "GraphVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the generated button above to see the factor graph via the NavAbility web App, which shows the structure between variables and factors.\n",
    "\n",
    "The factor graph figure shows the structure between variables and factors.  Note the two priors on `l1` and `l2`, because we have prior information telling us where those beacons are.  The first pose `x0` is only connected via the range measurements, with no prior info about the starting location.  Also no prior info about the location of beacon `l3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Visualizations\n",
    "\n",
    "At this point we can call the solver and interpret the first results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_id = await solveSession(navability_client, client)\n",
    "await waitForCompletion(navability_client, [result_id], maxSeconds=120)\n",
    "print('running solve...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of tools are provided by the RoMEPlotting packages to show the numerical values contained in the factor graph solution.\n",
    "\n",
    "First look at the two landmark positions `:l1`, `:l2` at `(10.0,30)`, `(30.0,-30)` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBelief(fg, [:l1;:l2], levels=5, c=[\"cyan\"; \"black\"])\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Location is Bi-Modal After Solve\n",
    "\n",
    "Similarly, the belief estimate for the first vehicle position `:x0` is bi-modal, due to the intersection of two range measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBelief(fg, :x0, levels=5, c=[\"red\"])\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the first 'robot' positon in this localization and mapping problem is not associated with by a prior factor of any kind.  The initial position could have been anywhere, but the two range measurements to known landmarks limited the uncertainty as shown in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Gaussian Estimate of the Unknown Beacon `:l3`\n",
    "\n",
    "In contrast to the known beacons `:l1` and `:l2` which have unimodal position estimates in the solution (owing to the prior information/assumptions on each), the belief over the position of unknown landmark `:l3` is simultaneously resolved to a posterior estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBelief(fg, :l3, levels=10, c=[\"pink\"])\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `:l3`'s location belief (i.e. surveying/mapping) forms a ring around the only available measurement to `:l3` from `:x0`.  A unimodal solution for `:l3` **does not exist**.  In conventional linear modeling, we might say the system is [singular](https://en.wikipedia.org/wiki/Invertible_matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaining and Losing Modes (i.e. Hypotheses)\n",
    "\n",
    "Next consider the vehicle moving a distance of 50 units–-and by design the direction of travel is not known–-to the next true position. The video above gives away the vehicle position with the cyan line, showing travel in the shape of a lower case 'e'. The following function handles (pseudo odometry) factors as range-only between positions and range-only measurement factors to beacons as the vehice travels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a helper function that simulates how the robot moves and measures between ground truth positions.\n",
    "async def vehicle_drives(client, context, from_lbl, to_lbl, GTp, GTl, measurelimit=150.0):\n",
    "  currvar = await listVariables(client, context)\n",
    "  resIds = []\n",
    "  if not(to_lbl in currvar):\n",
    "    print(\"Adding new variable %s\" % to_lbl)\n",
    "    v = await addVariable(client, context, Variable(to_lbl, VariableType.Point2.value))\n",
    "    resIds.append(v)\n",
    "    # an odometry distance factor\n",
    "    rho = norm(GTp[from_lbl] - GTp[to_lbl])\n",
    "    ppr = Point2Point2Range(Z=Normal(rho, 3.0))\n",
    "    range_factor = Factor(\"%s%sf1\" % (from_lbl,to_lbl), \"Point2Point2Range\", [from_lbl,to_lbl], FactorData(fnc=ppr.dump()))\n",
    "    f = await addFactor(client, context, range_factor)\n",
    "    resIds.append(f)\n",
    "  else:\n",
    "    print(\"Variable node %s already in the factor graph.\" % to_lbl)\n",
    "  \n",
    "  beacons = GTl.keys()\n",
    "  for ll in beacons:\n",
    "    rho = norm(GTl[ll] - GTp[to_lbl])\n",
    "    # Add measurements to beacons/landmarks if within limit\n",
    "    if rho < measurelimit:\n",
    "      if not(ll in currvar):\n",
    "        print(\"Adding variable vertex %s, not yet in the session\" % ll)\n",
    "        v = await addVariable(client, context, Variable(ll, VariableType.Point2.value))\n",
    "        resIds.append(v)\n",
    "      ppr = Point2Point2Range(Z=Normal(rho, 3.0))\n",
    "      range_factor = Factor(\"%s%sf1\" % (to_lbl,ll), \"Point2Point2Range\", [to_lbl,ll], FactorData(fnc=ppr.dump()))\n",
    "      f = await addFactor(client, context, range_factor)\n",
    "      resIds.append(f)\n",
    "  \n",
    "  # wait to make sure all the new additions are ready\n",
    "  await waitForCompletion(client, resIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this function in Julia, a new member definition vehicle_drives_to! can be used line any other function. Julia will handle the just-in-time compiling for the type specific function required and cach the static code for repeat executions.\n",
    "\n",
    "> **Note**, The exclamation mark at the end of the function is not reserved syntax in Julia, it's just part of the UTF character set.  The exclamation does, however, serve as a Julia community convention to tell the caller that this function will modify the contents of at least one of the variables being passed into it – in this case the factor graph `fg` will be modified!\n",
    "\n",
    "Now the actual driving event can be added to the factor graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drive to location :x1, then :x2\n",
    "await vehicle_drives(navability_client, client, 'x0', 'x1', GTp, GTl)\n",
    "await vehicle_drives(navability_client, client, 'x1', 'x2', GTp, GTl)\n",
    "\n",
    "# see the graph\n",
    "GraphVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**, the distance traveled could be any combination of accrued direction and speeds, however, a straight line Gaussian error model is used to keep the visual presentation of this example as simple as possible.\n",
    "\n",
    "Lets solve the whole factor graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_id = await solveSession(navability_client, client)\n",
    "await waitForCompletion(navability_client, [result_id], maxSeconds=120)\n",
    "print('running solve...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Modal (i.e. Multi-Hypothesis) Solution\n",
    "\n",
    "Now lets look at the robot position marginal beliefs.  We'll use a slightly lower level plotting function, `plotBelief`, to show the posterior beliefs of the tree robot locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBelief(fg, [:x0; :x1; :x2], levels=5, c=[\"red\",\"green\",\"blue\"])\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the robot trajectory has 2+ hypotheses,\n",
    "- a) starting from `(0,0)` and traversing left to right, and \n",
    "- b) starting from `(50,-5)` and traversing left down.\n",
    "\n",
    "Both are valid solutions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolving Estimates for New Beacons `:l3` and `:l4`\n",
    "\n",
    "So far we have measurements to the **initially unknown beacons** as:\n",
    "- ranges to `:l3` were measured from all three robot positions `[:x0,:x1,:x2]`, and\n",
    "- ranges to `:l4` were only mearured from two robot positions `[:x1, :x2]`\n",
    "\n",
    "Can you guess what the posterior belief estimate on new beacons `:l3` or `:l4` are given the available information up this point?  Let's plot and see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBelief(fg, [:l3;:l4], levels=5, c=[\"pink\"; \"orange\"])\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two \"free\" beacons/landmarks `:l3,:l4` still have several modes each, implying insufficient data to constrain either to a conventional unimodal belief."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot Moves Two More Positions\n",
    "\n",
    "The robot drives further to collect more information, keeping in mind that so far that only the two known beacons `:l1` and `:l2` have unimodal posterior belief estimates!  All other variables in the system `[:l3;:l4; :x0;:x1;:x2]` have multi-modal belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await vehicle_drives(navability_client, client, 'x2', 'x3', GTp, GTl)\n",
    "await vehicle_drives(navability_client, client, 'x3', 'x4', GTp, GTl)\n",
    "\n",
    "result_id = await solveSession(navability_client, client)\n",
    "await waitForCompletion(navability_client, [result_id], maxSeconds=120)\n",
    "print('running solve...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Robot's Latest Position at `:x3`\n",
    "\n",
    "After the above factor graph solution, lets see what the latest robot position belief estimate looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBelief(fg, [:x0;:x1;:x2;:x3;:x4], levels=5) #, c=[\"red\";\"green\";\"blue\";\"magenta\"])\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how, even though several new range measurements were made, the posterior on `:x3` has an increasing number of modes!  The number of modes may vary from solution to solution, but at least two dominant modes should be visible.\n",
    "\n",
    "Modes are gained or lost based on a combination of the problem setup and nonparametric variations within each individual solve.  More dominant modes are more consistent, while 'weak' modes may come or go from one solve to the next.  If more compute resources are used, then more and more 'weaker' modes will be recovered.\n",
    "\n",
    "> Several solver parameters can be modified to control the compute load vs. multimodal tracking efficacy.  Join the [Caesar.jl Slack](https://join.slack.com/t/caesarjl/shared_invite/zt-ucs06bwg-y2tEbddwX1vR18MASnOLsw) conversations, or connect with [NavAbility.io](https://www.navability.io/) to learn more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first robot position `[:x0,:x1]` belief estimates didn't change much with the addition new information!  There are still active hypotheses in the trajectory estimates going from `:x0` to `:x1`.  Perhaps the reason for that is because the new landmarks `[:l3; :l4]` are yet to be constrained to a low number of modes, lets see..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress on Locating New Beacons `:l3` and `:l4`\n",
    "\n",
    "We expect the uncertainty on position estimates for the initially unknown beacons `[:l3;:l4]` to decrease as new measurements are added to the overall problem.  Let's look again at the new posteriors on `:l3` and `:l4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBelief(fg, [:l3;:l4], levels=5, c=[\"pink\"; \"orange\"])\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still multiple modes on both `:l3` and `:l4`!  We still have way too little information to resolve a unimodal estimate on either the robot positions or the new beacon locations!  The entire system remains underdetermined, i.e. singular!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving to Positions `:x5` and `:x6`\n",
    "\n",
    "The robot moves further through positions `:x5` and `:x6`, and let's solve again and look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await vehicle_drives(navability_client, client, 'x4', 'x5', GTp, GTl)\n",
    "await vehicle_drives(navability_client, client, 'x5', 'x6', GTp, GTl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_id = await solveSession(navability_client, client)\n",
    "await waitForCompletion(navability_client, [result_id], maxSeconds=120)\n",
    "print('running solve...')\n",
    "\n",
    "# plotBelief(fg, [Symbol(\"x$i\") for i=0:6], levels=3)\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviewing Landmark Location Estimates Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBelief(fg, [:l1;:l2;:l3;:l4], levels=5, c=[\"cyan\";\"black\";\"pink\"; \"orange\"])\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving to Positions `:x7` and `:x8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await vehicle_drives(navability_client, client, 'x6', 'x7', GTp, GTl)\n",
    "await vehicle_drives(navability_client, client, 'x7', 'x8', GTp, GTl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_id = await solveSession(navability_client, client)\n",
    "await waitForCompletion(navability_client, [result_id], maxSeconds=120)\n",
    "\n",
    "print('running solve...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBelief(fg, sortDFG(ls(fg, r\"x\\d\")), levels=5)\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we see a strong return to a single dominant mode in all vehicle position estimates, owing to the increased measurements to beacons/landmarks as well as more unimodal estimates in `:l3, :l4` beacon/landmark positions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several location belief estimates exhibit multimodality as the trajectory progresses (not shown), but collapses a stable set of dominant position estimates.  Landmark estimates are also stable at one estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotBelief(fg, [:l1;:l2;:l3;:l4], levels=4)\n",
    "MapVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also just look at what the factor graph looks like at this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphVizApp(client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Theoretically, should there be one or more overall trajectory hypotheses in the final result?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- This Tutorial showed [ONE OF FOUR](https://juliarobotics.org/Caesar.jl/latest/concepts/why_nongaussian/) identified mechanisms how non-Gaussian behavior can enter a localization and mapping system.  See the other tutorials and material for similar discussions on other mechanism by which multi-modal posteriors manifest.\n",
    "- For a longer version of this example, see [open-source solver documentation here](https://juliarobotics.org/Caesar.jl/latest/examples/basic_slamedonut/).\n",
    "\n",
    "Visit [www.NavAbility.io](https://www.NavAbility.io) for more about how to use these and other advanced navigation features in your application."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
