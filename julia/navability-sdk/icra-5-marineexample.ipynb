{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDER CONSTRUCTION\n",
    "\n",
    "Please note this notebook is being developed for ICRA2022, please see earlier for tutorial notebooks that have been completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5: Less Time Wrangling Data, More Time Understanding/Actioning it\n",
    "\n",
    "**API Version: JuliaLang NavAbilitySDK.jl**\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "Marine operations in harbor and populated river environments will see increased autonomy with major benefits for safety and efficacy, but the navigational environment poses a number of vital challenges.  In developing and testing proof-of-concept systems, four very specific challenges arose:\n",
    "- GPS data can occasionaly drop out, specifically when maneuvering under bridges or between tall structures;\n",
    "- Various perception sensors each perform really well with reasonable availability for seeing obstacles or aiding navigation, but no one sensor alone provides a home run solution;\n",
    "- Practical development testing an operations produces large amounts of recorded robot data, but the data quickly becomes overwhelming and difficult to action;\n",
    "- How to share / integrate measurement data and navigation between agents (human or autonomous), as well as with shore side operations;\n",
    "\n",
    "### The Solution\n",
    "\n",
    "Using the NavAbility Platform, we developed a case study for marine vehicle navigation which direclty addresses these problems.  The underlying SLAM solver is supported by NavAbility as open core software.  Links to the open source code and deeper discussions are available by following links from [the relevant Blog post](https://www.navability.io/2022/02/04/application-example-marine-vehicle-mapping-systems-for-collision-avoidance-and-planning/).\n",
    "\n",
    "This tutorial below shows how to interact with similar data quickly, efficiently, and with maximum ease.  This tutorial builds on previous tutorials that show how and why factor graphs are so important, as well other tutorials showing some of the robust (non-Gaussian) solver features that are available when building multi-sensor navigation and mapping systems that must combine challenging, ambiguous, and contradictory measurements and data cues.\n",
    "\n",
    "### The Value (Broader Application)\n",
    "\n",
    "- By being able to rapidly develop advanced multisensor perception, localization, and mapping ideas drastically reduces the cost and risk of introducing highly focussed autonomy/safety features into existing operations.\n",
    "- Access to both raw data and actionable SLAM results provides a major platform for machine learning tasks, such as training predictors that have either geometric of semantic relevance -- e.g. learning vehicle behaviors or better classifiers.\n",
    "- Access to a temporal/spatial database allows various sessions to be brought together with NavAbility's map merging technology -- this will be the discussed more in a future tutorial.\n",
    "\n",
    "By providing these features through platform and open community, NavAbility is working to give you access to the similar capabilities that marjor brands like Tesla or Amazon are developing privately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Marine SLAM Solution\n",
    "\n",
    "The marine case study shows benefits value of persistent simultaneous localization and mapping SLAM solutions.\n",
    "```\n",
    "Raw Data --> NavAbility Platform SLAM Solving -----> Action / Visualize Results\n",
    "          ^                                    |\n",
    "          |                                    |\n",
    "        Enhance the  <--------------- Deeper processing of data\n",
    "        factor graph                    with previous resutls\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data is Alive and Available\n",
    "\n",
    "> Sketch how the data exists\n",
    "\n",
    "- Show that the factor graph exists\n",
    "- Show the size of the factor graph\n",
    "- Show which variables and factors are in the factor graph\n",
    "\n",
    "In the sections hereafter, you will learn more about which data is being stored in each of these graph nodes, how the SLAM solution is processed and why that is crucial for multisensor navigation, and how to immediately interact the data on the platform for youself. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary packages or accesing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NavAbilitySDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read-only Data, `userId=examples@navability.io`\n",
    "\n",
    "### Robot:Session => MarineASV_ICRA2022:Tutorial5_1000\n",
    "\n",
    "Point the SDK context to the right location, but selecting the User:Robot:Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Client: User=examples@navability.io, Robot=MarineASV_ICRA2022, Session=Tutorial5_1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = NavAbilityHttpsClient()\n",
    "\n",
    "# you need a unique userId:robotId, and can keep using that across all tutorials\n",
    "userId = \"examples@navability.io\"\n",
    "robotId = \"MarineASV_ICRA2022\"\n",
    "sessionId = \"Tutorial5_1000\"\n",
    "\n",
    "context = Client(userId, robotId, sessionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables in Session?\n",
    "\n",
    "To get a sense of scale of the dataset, we can look at the number of variables under this session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58-element Vector{String}:\n",
       " \"x284\"\n",
       " \"x274\"\n",
       " \"x279\"\n",
       " \"x259\"\n",
       " \"x254\"\n",
       " \"x249\"\n",
       " \"x234\"\n",
       " \"x244\"\n",
       " \"x239\"\n",
       " \"x0\"\n",
       " ⋮\n",
       " \"x199\"\n",
       " \"x204\"\n",
       " \"x209\"\n",
       " \"x214\"\n",
       " \"x219\"\n",
       " \"x224\"\n",
       " \"x229\"\n",
       " \"x269\"\n",
       " \"x264\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lbls = listVariables(client, context) |> fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 9 entries:\n",
       "  \"label\"        => \"x284\"\n",
       "  \"solverData\"   => Any[Dict{String, Any}(\"dimval\"=>3, \"dontmargin\"=>false, \"Ba…\n",
       "  \"ppes\"         => Any[Dict{String, Any}(\"max\"=>Any[1580.4, 118.766, -0.061349…\n",
       "  \"smallData\"    => \"{}\"\n",
       "  \"variableType\" => \"RoME.Pose2\"\n",
       "  \"tags\"         => Any[\"VARIABLE\", \"POSE\"]\n",
       "  \"timestamp\"    => \"2022-05-22T05:21:51.440Z\"\n",
       "  \"_version\"     => \"0.18.3\"\n",
       "  \"solvable\"     => 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v284 = getVariable(client, context, \"x284\") |> fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Are the Variables Initialized?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v284[\"solverData\"][1][\"initialized\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is the Graph solved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v284[\"solverData\"][1][\"solvedCount\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Data Blobs\n",
    "\n",
    "The solution supports storing large data blobs.\n",
    "\n",
    "### List Data Entries\n",
    "\n",
    "Data blobs can be associated with a variable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: listDataEntries not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: listDataEntries not defined\n",
      "\n",
      "Stacktrace:\n",
      "  [1] getproperty(x::Module, f::Symbol)\n",
      "    @ Base ./Base.jl:35\n",
      "  [2] top-level scope\n",
      "    @ ~/software/NavAbility/BinderNotebooks/julia/navability-sdk/icra-5-marineexample.ipynb:1\n",
      "  [3] eval\n",
      "    @ ./boot.jl:373 [inlined]\n",
      "  [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)\n",
      "    @ Base ./loading.jl:1196\n",
      "  [5] #invokelatest#2\n",
      "    @ ./essentials.jl:716 [inlined]\n",
      "  [6] invokelatest\n",
      "    @ ./essentials.jl:714 [inlined]\n",
      "  [7] (::VSCodeServer.var\"#164#165\"{VSCodeServer.NotebookRunCellArguments, String})()\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.6.17/scripts/packages/VSCodeServer/src/serve_notebook.jl:19\n",
      "  [8] withpath(f::VSCodeServer.var\"#164#165\"{VSCodeServer.NotebookRunCellArguments, String}, path::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.6.17/scripts/packages/VSCodeServer/src/repl.jl:184\n",
      "  [9] notebook_runcell_request(conn::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, params::VSCodeServer.NotebookRunCellArguments)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.6.17/scripts/packages/VSCodeServer/src/serve_notebook.jl:13\n",
      " [10] dispatch_msg(x::VSCodeServer.JSONRPC.JSONRPCEndpoint{Base.PipeEndpoint, Base.PipeEndpoint}, dispatcher::VSCodeServer.JSONRPC.MsgDispatcher, msg::Dict{String, Any})\n",
      "    @ VSCodeServer.JSONRPC ~/.vscode/extensions/julialang.language-julia-1.6.17/scripts/packages/JSONRPC/src/typed.jl:67\n",
      " [11] serve_notebook(pipename::String, outputchannel_logger::Base.CoreLogging.SimpleLogger; crashreporting_pipename::String)\n",
      "    @ VSCodeServer ~/.vscode/extensions/julialang.language-julia-1.6.17/scripts/packages/VSCodeServer/src/serve_notebook.jl:136\n",
      " [12] top-level scope\n",
      "    @ ~/.vscode/extensions/julialang.language-julia-1.6.17/scripts/notebook/notebook.jl:32\n",
      " [13] include(mod::Module, _path::String)\n",
      "    @ Base ./Base.jl:418\n",
      " [14] exec_options(opts::Base.JLOptions)\n",
      "    @ Base ./client.jl:292\n",
      " [15] _start()\n",
      "    @ Base ./client.jl:495"
     ]
    }
   ],
   "source": [
    "NVA.listDataEntries(client, \"x9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bring your own Visualizer (BYOV)\n",
    "\n",
    "We expect most applications already have a dedicated visualizer techonology choice, and this is good.  The localization and mapping processing here is focussed on providing robust and distributed **results which can be incorporated into existing visualization frameworks**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic awareness, App Geometric Visualization\n",
    "\n",
    "To make this tutorial accessible, we show the Marine Case study data with the NavAbility App, which provides a basic 2D visualizer to get a basic understanding of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.navability.io/cloud/map/?userId=examples@navability.io&robotStartsWith=MarineASV_ICRA2022&sessionStartsWith=Tutorial5_1000\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "[![Navigate to Factor Graph](http://www.navability.io/wp-content/uploads/2022/03/geometric_map.png)](https://app.navability.io/cloud/map/?userId=examples@navability.io&robotStartsWith=MarineASV_ICRA2022&sessionStartsWith=Tutorial5_1000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Map with/without GPS\n",
    "\n",
    "A major emphasis of this tutorial is highlighting the importance of robust navigation from all sensors and data sources, while knowing that each sensor has it's own problems and is unlikely to work perfectly 100% of the time -- e.g. GPS fails under bridges when being jammed, cameras fail when the sun or reflections are in the field of view, and radar cross section detections and shadows can vary significatnly.  By embracing non-Gaussian / multimodal data processing challenges head on, we are able to add significant value to the ease and robustness with which the necessary localization / mapping / tracking solutions that need to be developed.\n",
    "\n",
    "[![Marine Appl Ex](http://www.navability.io/wp-content/uploads/2022/04/MarineRadarAlignFigure-1024x485-1.png)](https://www.navability.io/2022/02/04/application-example-marine-vehicle-mapping-systems-for-collision-avoidance-and-planning/)\n",
    "\n",
    "Pull two radar sweeps and show a slice of the correlation maps from ScatterAlignPose2 -- discuss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors in the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58-element Vector{String}:\n",
       " \"x0x4f_843d\"\n",
       " \"x0f_ca58\"\n",
       " \"x279x284f1\"\n",
       " \"x274x279f1\"\n",
       " \"x269x274f1\"\n",
       " \"x264x269f1\"\n",
       " \"x259x264f1\"\n",
       " \"x254x259f1\"\n",
       " \"x249x254f1\"\n",
       " \"x244x249f1\"\n",
       " ⋮\n",
       " \"x44x49f1\"\n",
       " \"x39x44f1\"\n",
       " \"x34x39f1\"\n",
       " \"x29x34f1\"\n",
       " \"x24x29f1\"\n",
       " \"x19x24f1\"\n",
       " \"x14x19f1\"\n",
       " \"x9x14f1\"\n",
       " \"x4x9f1\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "listFactors(client, context) |> fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look a bit closer at one of the radar odometry factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 8 entries:\n",
       "  \"label\"                 => \"x4x9f1\"\n",
       "  \"_variableOrderSymbols\" => Any[\"x4\", \"x9\"]\n",
       "  \"data\"                  => \"eyJlbGltaW5hdGVkIjpmYWxzZSwicG90ZW50aWFsdXNlZCI6Z…\n",
       "  \"tags\"                  => Any[\"FACTOR\"]\n",
       "  \"timestamp\"             => \"2022-05-24T05:34:17.016Z\"\n",
       "  \"_version\"              => \"0.18.3\"\n",
       "  \"fnctype\"               => \"ScatterAlignPose2\"\n",
       "  \"solvable\"              => 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_x4x9 = getFactor(client, context, \"x4x9f1\") |> fetch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the line above shows a \"data\" value which in this particular case is a `base64` encoded string.  That field contains the data for a `Caesar.ScatterAlignPose2` factor -- also shows by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ScatterAlignPose2\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f_x4x9[\"fnctype\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find / Track Obstacles with NavAbilitySDK\n",
    "\n",
    "### Large Data Blobs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Find Boats in Camera Data\n",
    "\n",
    "- Pull image data,\n",
    "- Process camera image with user side needs,\n",
    "\n",
    "### Track Boats in the Radar Data\n",
    "\n",
    "### Combining Camera / Radar info Back into Factor Graph\n",
    "\n",
    "- Dummy stub for uploading data back (not allowed under guest, please sign up for write access to a session)\n",
    "- Pull all this data into the factor graph and ask for a new solve\n",
    "\n",
    "### We Baked one Earlier\n",
    "\n",
    "- Show a piece of the factor graph where a target object boat is being tracked by both camera and radar factors in the graph,\n",
    "- Visualize the trajectory of the target boat, which was estimated from our vehicle regardless of whether GPS was working or not!\n",
    "\n",
    "### Query spatial relationships,\n",
    "\n",
    "- What is here there, or nearby\n",
    "- What might see this target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Next Steps\n",
    "\n",
    "If you have interest in NavAbility and what our technology can do, please reach out via [Slack](https://join.slack.com/t/caesarjl/shared_invite/zt-ucs06bwg-y2tEbddwX1vR18MASnOLsw) or [info@navability.io](info@navability.io)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
