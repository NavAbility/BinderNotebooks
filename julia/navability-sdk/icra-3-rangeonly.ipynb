{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: Insufficient Data (2D Range-only)\n",
    "\n",
    "**API Version: Julia NavAbilitySDK.jl**\n",
    "\n",
    "**Keywords:** Range-only, factor graph, under-determined, localization, mapping, SLAM, missing data, insufficient data, robotics, inference, Bayes tree, junction tree\n",
    "\n",
    "## Overview\n",
    "\n",
    "This example shows how non-Gaussian solutions occur from weak observability of desired variables from available data.  For this tutorial, we imagine a robot traveling around on a flat surface, in a rectangular trajectory making range measurements to beacons.  Let's assume WiFi power levels are used as a proxy for range measurements in this case.\n",
    "\n",
    "<img src=\"https://github.com/NavAbility/BinderNotebooks/raw/main/static/icra-3/example-wifi.png\" width=800>\n",
    "\n",
    "To illustrate the the underdetermined solution aspect, we simplify the problem in that WiFi ranging is assumed to produce a pure unimodal (Gaussian) measurement.  This tutorial will show how non-Gaussian behavior can arise because tha variables are weakly or underconstrained by the available measurement dimensions.  This tutorial is designed such that this occurs throughout the entire problem.\n",
    "\n",
    "We build a factor graph in stages as the robot moves around the environment through pose/keyframe epochs.  The factor graph will be solved with the [open core Caesar.jl solver](https://github.com/JuliaRobotics/Caesar.jl) at each pose epoch, which produces the posterior marginal beliefs on each of the variables in the system.  After each pose epoch solution, we will look at the marginal belief estimates of all the variables in the system.\n",
    "\n",
    "We assume the robot is traveling on a XY plane, starting at the origin along X and turning left along Y, then negative X, negative Y back to the origin.  Only four WiFi beacons are in the environment where the robot is moving.  Measurements to the WiFi beacons can only be included with there if the signal is within range.  Two of the beacon locations are known as prior information, while the other two beacons are at an unknown location and their location will be eastimated simultaneously to the robot pose location in the same factor graph system -- making this a simultaneous localization and mapping (SLAM) problem.\n",
    "\n",
    "To further simplify the tutorial, the \"odometry\" measurement between consecutive poses  are also taken as range-only (i.e. distance-only) measurements.  These \"odometry\" factors provide less information than conventional wheel or visual odometry constraints might provide.\n",
    "\n",
    "This tutorial shows [one of four mechanisms](https://juliarobotics.org/Caesar.jl/latest/concepts/why_nongaussian/) that can intoduce non-Gaussian behavior into a factor graph system, see other examples for other mechanisms.  Note that the techniques used in this tutorial can readily be combined with with methods from other tutorials.  For example, the pure Gaussian measurement ranging models used here can be replaced with ambiguous measurements shown in ICRA Tutorial 2.  Or, can be combined with uncertain data association (i,e. multi-hypothesis) measurement models for unknown beacon associations similat to the technique used in ICRA Tutorial 4.  Learn more from our peer-reviewed publications listed here: `CJLDocs/Literature`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signatures Used\n",
    "\n",
    "`Point2`, `PriorPoint2`, `Point2Point2Range`, `MvNormal`, `Normal`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading The Data\n",
    "\n",
    "The ground truth positions for vehicle positions GTp and landmark positions GTl can be loaded into memory directly with these values.  **Note,** we are using variable names\n",
    "- `l1, l2` as ranging beacons with known locations,\n",
    "- `l3, l4` as ranging beacons with initially unknown locations,  \n",
    "\n",
    "These beacon landmarks must be in range before measurements can be made to them.  For the tutorial, we imagine a robot moving from one position to the next in the XY space between the landmarks.  We use ground truth positions to build the simulation, while the SLAM solution has to resolve estimates of the variables as the main exercise of the tutorial.  The robot positions are denoted as\n",
    "- `x0, x1, ...`.\n",
    "\n",
    "Ground truth data is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our dictionary of vehicle positions\n",
    "GTp = Dict{Symbol, Vector{Float64}}()\n",
    "GTp[:x0] = [0.0;0]\n",
    "GTp[:x1] = [50.0;0]\n",
    "GTp[:x2] = [100.0;0]\n",
    "GTp[:x3] = [100.0;50.0]\n",
    "GTp[:x4] = [100.0;100.0]\n",
    "GTp[:x5] = [50.0;100.0]\n",
    "GTp[:x6] = [0.0;100.0]\n",
    "GTp[:x7] = [0.0;50.0]\n",
    "GTp[:x8] = [0.0;-50.0]\n",
    "\n",
    "# Our dictionary of landmark positions\n",
    "GTl = Dict{Symbol, Vector{Float64}}()\n",
    "GTl[:l1] = [10.0;30]\n",
    "GTl[:l2] = [30.0;-30]\n",
    "GTl[:l3] = [80.0;40]\n",
    "GTl[:l4] = [120.0;-50];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Necessary Packages\n",
    "\n",
    "An optional install line is kept here in case the packages are not yet installed in your environment for whatever reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional install of packages, in case they are not available in your environment for whatever reason\n",
    "import Pkg; Pkg.add(\"NavAbilitySDK\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary packages,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NavAbilitySDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Factor Graph\n",
    "\n",
    "After loading the requried packages, lets start creating the factor graph using variables of type `Point2` (a.k.a. `Postion2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need a unique userId:robotId, and can keep using that across all tutorials\n",
    "userId = \"Guest\"\n",
    "robotId = \"SDKjl_\"*(string(uuid4())[1:4])\n",
    "\n",
    "# also create a client connection\n",
    "client = NavAbilityHttpsClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You'll need a unique session number each time you run a new graph\n",
    "sessionId = \"Tutorial3_\"*(string(uuid4())[1:4])\n",
    "# context is the object to use below\n",
    "context = Client(userId,robotId,sessionId)\n",
    "\n",
    "# convenience Tuple\n",
    "nvapl = client, context;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all the async responses and wait at the end\n",
    "resultIds = Task[]\n",
    "\n",
    "# first pose with no prior info about the initial numerical estimate\n",
    "push!(resultIds, \n",
    "  addVariable(nvapl..., Variable(\"x0\", :Point2))\n",
    ");\n",
    "\n",
    "# add three landmarks\n",
    "for lbl in [\"l1\";\"l2\";\"l3\"]\n",
    "  push!(resultIds, \n",
    "    addVariable(nvapl..., Variable(lbl, :Point2))\n",
    "  );\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial graph also has prior location information about each of the known beacons/landmarks `l1` and `l2`.  Let's go ahead and add those as factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put prior on l1\n",
    "f = Factor(\"l1f1\", \"PriorPoint2\", [\"l1\"], \n",
    "  PriorPoint2Data(\n",
    "    Z=FullNormal( GTl[:l1], diagm(ones(2)) )\n",
    "  )\n",
    ")\n",
    "push!(resultIds, addFactor(nvapl..., f));\n",
    "\n",
    "# put prior on l2\n",
    "f = Factor(\"l2f1\", \"PriorPoint2\", [\"l2\"], \n",
    "  PriorPoint2Data(\n",
    "    Z=FullNormal( GTl[:l2], diagm(ones(2)) )\n",
    "  )\n",
    ")\n",
    "push!(resultIds, addFactor(nvapl..., f));\n",
    "\n",
    "# wait to make sure all the new additions are ready\n",
    "waitForCompletion(client, resultIds; expectedStatuses=[\"Complete\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PriorPoint2` is assumed to be a multivariate normal distribution of covariance `diagm(ones(2))`. Note the API `PriorPoint2(::SamplableBelief)` accepts any of the distribution objects that the Caesar.jl libraries support -- this is discussed further in subsection [Various `SamplableBelief` Distribution types](https://juliarobotics.org/Caesar.jl/latest/concepts/dataassociation/#Various-SamplableBelief-Distribution-Types)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Range Measurements Between Variables\n",
    "\n",
    "Next we connect the three range measurements from the vehicle location `x0` to the three beacon landmarks `l1`, `l2`, and `l3`, respectively â€“ and consider that the range measurements are completely relative between the vehicle and beacon position estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first range measurement from x0 to l1\n",
    "rhoZ1 = norm(GTl[:l1]-GTp[:x0])\n",
    "f = Factor(\"x0l1f1\", \"Point2Point2Range\", [\"x0\";\"l1\"], \n",
    "  Point2Point2RangeData(\n",
    "    range=Normal(rhoZ1, 2)\n",
    "  )\n",
    ")\n",
    "push!(resultIds, addFactor(nvapl..., f));\n",
    "\n",
    "# second range measurement from x0 to l2\n",
    "rhoZ2 = norm(GTl[:l2]-GTp[:x0])\n",
    "f = Factor(\"x0l2f1\", \"Point2Point2Range\", [\"x0\";\"l2\"], \n",
    "  Point2Point2RangeData(\n",
    "    range=Normal(rhoZ2, 2)\n",
    "  )\n",
    ")\n",
    "push!(resultIds, addFactor(nvapl..., f));\n",
    "\n",
    "# third range measurement from x0 to l3\n",
    "rhoZ3 = norm(GTl[:l3]-GTp[:x0])\n",
    "f = Factor(\"x0l3f1\", \"Point2Point2Range\", [\"x0\";\"l3\"], \n",
    "  Point2Point2RangeData(\n",
    "    range=Normal(rhoZ3, 2)\n",
    "  )\n",
    ")\n",
    "push!(resultIds, addFactor(nvapl..., f));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranging measurement standard deviation of 2.0 or 3.0 is taken, assuming a Gaussian measurement assumption. Again, any distribution could have been used. The factor graph should look as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the generated factor graph graphic to open NavAbility App visualization\n",
    "GraphVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The factor graph figure above shows the structure between variables and factors.  Note the two priors on `l1` and `l2`, because we have prior information telling us where those beacons are.  The first pose `x0` is only connected via the range measurements, with no prior info about the starting location.  Also no prior info about the location of beacon `l3`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and Visualizations\n",
    "\n",
    "At this point we can call the solver and interpret the first results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push!(resultIds,\n",
    "  solveSession(client, context)\n",
    ");\n",
    "\n",
    "# Give it a few seconds JIT compiling during first run.\n",
    "println(\"running solve...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization tools for awarenss via the NavAbilty WebApp, to show the numerical values contained in the factor graph solution.\n",
    "\n",
    "First look at the two landmark positions `l1`, `l2` at `(10.0,30)`, `(30.0,-30)` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on the generated factor graph graphic to open NavAbility App visualization\n",
    "# plotBelief(fg, [:l1;:l2], levels=5, c=[\"cyan\"; \"black\"])\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click on the generated \"Geometric Map\" graphic above to see a visualization of latest numerical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Location is Bi-Modal After Solve\n",
    "\n",
    "Similarly, the belief estimate for the first vehicle position `x0` is bi-modal, due to the intersection of two range measurements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = plotBelief(fg, :x0, levels=5, c=[\"red\"])\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, the first 'robot' positon in this localization and mapping problem is not associated with by a prior factor of any kind.  The initial position could have been anywhere, but the two range measurements to known landmarks limited the uncertainty as shown in the plot above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Gaussian Estimate of the Unknown Beacon `l3`\n",
    "\n",
    "In contrast to the known beacons `l1` and `l2` which have unimodal position estimates in the solution (owing to the prior information/assumptions on each), the belief over the position of unknown landmark `l3` is simultaneously resolved to a posterior estimate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = plotBelief(fg, :l3, levels=10, c=[\"pink\"])\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how `l3`'s location belief (i.e. surveying/mapping) forms a ring around the only available measurement to `l3` from `x0`.  A unimodal solution for `l3` **does not exist**.  In conventional linear modeling, we might say the system is [singular](https://en.wikipedia.org/wiki/Invertible_matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaining and Losing Modes (i.e. Hypotheses)\n",
    "\n",
    "Next consider the vehicle moving a distance of 50 unitsâ€“-and by design the direction of travel is not knownâ€“-to the next true position. The video above gives away the vehicle position with the cyan line, showing travel in the shape of a lower case 'e'. The following function handles (pseudo odometry) factors as range-only between positions and range-only measurement factors to beacons as the vehice travels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a helper function that simulates how the robot moves and measures between ground truth positions. \n",
    "function vehicle_drives(\n",
    "    CliCon::Tuple, \n",
    "    from_lbl::String, \n",
    "    to_lbl::String, \n",
    "    GTp::Dict, GTl::Dict; \n",
    "    measurelimit=150.0\n",
    "  )\n",
    "  #\n",
    "  # client, context = CliCon\n",
    "  resIds = Task[]\n",
    "  # example with stateless local instance, various stateful distributed architectures are supported\n",
    "  currvar = listVariables(CliCon...) |> fetch\n",
    "  if !(to_lbl in currvar)\n",
    "    println(\"Adding new variable $to_lbl\")\n",
    "    push!(resIds, addVariable(CliCon..., Variable(to_lbl, :Point2)));\n",
    "    # an odometry distance factor\n",
    "    @show rho = norm(GTp[Symbol(from_lbl)] - GTp[Symbol(to_lbl)])\n",
    "    f = Factor(\"$(from_lbl)$(to_lbl)f1\", \"Point2Point2Range\", [from_lbl;to_lbl], \n",
    "          Point2Point2RangeData(\n",
    "            range=Normal(rho, 3.0)\n",
    "        ))\n",
    "    push!(resIds, addFactor(CliCon..., f));\n",
    "  else\n",
    "    @warn \"Variable node $to_lbl already in the factor graph.\"\n",
    "  end\n",
    "  beacons = string.(keys(GTl))\n",
    "  for ll in beacons\n",
    "    rho = norm(GTl[Symbol(ll)] - GTp[Symbol(to_lbl)])\n",
    "    # Add measurements to beacons/landmarks if within limit\n",
    "    if rho < measurelimit\n",
    "      if !(ll in currvar)\n",
    "        println(\"Adding variable vertex $ll, not yet in fgl<:AbstractDFG.\")\n",
    "        push!(resIds, addVariable(CliCon..., Variable(ll, :Point2)));\n",
    "      end\n",
    "      f = Factor(\"$(to_lbl)$(ll)f1\", \"Point2Point2Range\", [to_lbl;ll],\n",
    "            Point2Point2RangeData(\n",
    "              range=Normal(rho, 3.0)\n",
    "          ))\n",
    "      push!(resIds, addFactor(CliCon..., f));\n",
    "    end\n",
    "  end\n",
    "  # wait to make sure all the new additions are ready\n",
    "  waitForCompletion(client, resultIds; expectedStatuses=[\"Complete\"])\n",
    "  nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running this function in Julia, a new member definition `vehicle_drives_to!` can be used line any other function. Julia will handle the just-in-time compiling for the type specific function required and cach the static code for repeat executions.\n",
    "\n",
    "Now the actual driving event can be added to the factor graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drive to location :x1, then :x2\n",
    "vehicle_drives(nvapl, \"x0\", \"x1\", GTp, GTl)\n",
    "vehicle_drives(nvapl, \"x1\", \"x2\", GTp, GTl)\n",
    "\n",
    "# see the graph\n",
    "GraphVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**, the distance traveled could be any combination of accrued direction and speeds, however, a straight line Gaussian error model is used to keep the visual presentation of this example as simple as possible.\n",
    "\n",
    "Lets solve the whole factor graph again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push!(resultIds,\n",
    "  solveSession(client, context)\n",
    ");\n",
    "\n",
    "# Give it a few seconds JIT compiling during first run.\n",
    "println(\"running solve...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Modal (i.e. Multi-Hypothesis) Solution\n",
    "\n",
    "Now lets look at the robot position marginal beliefs.  We'll use a slightly lower level plotting function, `plotBelief`, to show the posterior beliefs of the tree robot locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = plotBelief(fg, [:x0; :x1; :x2], levels=5, c=[\"red\",\"green\",\"blue\"])\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the robot trajectory has 2+ hypotheses,\n",
    "- a) starting from `(0,0)` and traversing left to right, and \n",
    "- b) starting from `(50,-5)` and traversing left down.\n",
    "\n",
    "Both are valid solutions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolving Estimates for New Beacons `l3` and `l4`\n",
    "\n",
    "So far, we have added measurements to the **initially unknown beacons**:\n",
    "- ranges to `l3` were measured from all three robot positions `[x0,x1,x2]`, and\n",
    "- ranges to `l4` were only mearured from two robot positions `[x1, x2]`\n",
    "\n",
    "Can you guess what the posterior belief estimate on new beacons `l3` or `l4` are given the available information up this point?  Let's plot and see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = plotBelief(fg, [:l3;:l4], levels=5, c=[\"pink\"; \"orange\"])\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two \"free\" beacons/landmarks `l3,l4` still have several modes each, implying insufficient data to constrain either to a conventional unimodal belief.  These marginal posteriors are clearly non-Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot Moves Two More Positions\n",
    "\n",
    "The robot drives further to collect more information, keeping in mind that so far that only the two known beacons `l1` and `l2` have unimodal posterior belief estimates!  All other variables in the system `[l3;l4; x0;x1;x2]` have multi-modal belief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_drives(nvapl, \"x2\", \"x3\", GTp, GTl)\n",
    "vehicle_drives(nvapl, \"x3\", \"x4\", GTp, GTl)\n",
    "\n",
    "push!(resultIds,\n",
    "  solveSession(client, context)\n",
    ");\n",
    "\n",
    "# Give it a few seconds JIT compiling during first run.\n",
    "println(\"running solve...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating the Robot's Latest Position at `x3`, `x4`\n",
    "\n",
    "After the above factor graph solution, the latest robot position belief estimate is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = plotBelief(fg, [:x0;:x1;:x2;:x3;:x4], levels=5)\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how, even though several new range measurements were made, the posterior on `x3` has an increasing number of modes!  The number of modes may vary from solution to solution, but at least two dominant modes should be visible.\n",
    "\n",
    "Modes are gained or lost based on a combination of the problem setup and nonparametric variations within each individual solve.  More dominant modes are more consistent, while 'weak' modes may come or go from one solve to the next.  If more compute resources are used, then more and more 'weaker' modes will be recovered.\n",
    "\n",
    "> Several solver parameters can be modified to control the compute load vs. multimodal tracking efficacy.  Join the [Caesar.jl Slack](https://join.slack.com/t/caesarjl/shared_invite/zt-ucs06bwg-y2tEbddwX1vR18MASnOLsw) conversations, or connect with [NavAbility.io](https://www.navability.io/) to learn more.\n",
    "\n",
    "The first robot position `[x0,x1]` belief estimates didn't change much with the addition new information!  There are still active hypotheses in the trajectory estimates going from `x0` to `x1`.  Perhaps the reason for that is because the new landmarks `[l3; l4]` are yet to be constrained to a low number of modes, lets see..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress on Locating New Beacons `l3` and `l4`\n",
    "\n",
    "We expect the uncertainty on position estimates for the initially unknown beacons `[l3;l4]` to decrease as new measurements are added to the overall problem.  Let's look again at the new posteriors on `l3` and `l4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = plotBelief(fg, [:l3;:l4], levels=5, c=[\"pink\"; \"orange\"])\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still multiple modes on both `l3` and `l4`!  We still have way too little information to resolve a unimodal estimate on either the robot positions or the new beacon locations!  The entire system remains underdetermined, i.e. singular!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving to Positions `x5` and `x6`\n",
    "\n",
    "The robot moves further through positions `x5` and `x6`, and let's solve again and look at the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_drives(nvapl, \"x4\", \"x5\", GTp, GTl)\n",
    "vehicle_drives(nvapl, \"x5\", \"x6\", GTp, GTl)\n",
    "\n",
    "push!(resultIds,\n",
    "  solveSession(client, context)\n",
    ");\n",
    "\n",
    "# Give it a few seconds JIT compiling during first run.\n",
    "println(\"running solve...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = plotBelief(fg, [Symbol(\"x$i\") for i=0:6], levels=3)\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviewing Landmark Location Estimates Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = plotBelief(fg, [:l1;:l2;:l3;:l4], levels=5, c=[\"cyan\";\"black\";\"pink\"; \"orange\"])\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving to Positions `x7` and `x8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_drives(nvapl, \"x6\", \"x7\", GTp, GTl)\n",
    "vehicle_drives(nvapl, \"x7\", \"x8\", GTp, GTl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "push!(resultIds,\n",
    "  solveSession(client, context)\n",
    ");\n",
    "\n",
    "# Give it a few seconds JIT compiling during first run.\n",
    "println(\"running solve...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the list function, we can recover all the variables of interest, and then use for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @show lbls = sortDFG(ls(fg, r\"x\\d\")); pl = plotBelief(fg, lbls, levels=5)\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the nonparametric solution has stochastic behaviou, the main modes of the position estimates are successfully tracked.  Smaller modes may also show up in some of the marginal estimates.  The correct solution does have multiple modes.  Part of our ongoing open core solver improvements is to improve mode tracking quality with less computation.  We stress that this tutorial is designed to showcase the variability from more modes, and that many practical applications can already benefit from this existing solver robustness to underdetermined situations.\n",
    "\n",
    "Concurrently, the landmark estimates are also exhibit ongoing multimodality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pl = plotBelief(fg, [:l1;:l2;:l3;:l4], levels=4, c=[\"cyan\";\"black\";\"pink\"; \"orange\"])\n",
    "MapVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still multi-modality on landmark position estimates!  This indicates the uncertain nature of the problem which is driven by weak observabilty.  To round out the tutorial, let's see what the factor graph looks like at this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GraphVizApp(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Theoretically, should there be one or more overall trajectory hypotheses in the final result?\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- This Tutorial showed [one of four](https://juliarobotics.org/Caesar.jl/latest/concepts/why_nongaussian/) identified mechanisms how non-Gaussian behavior can enter a localization and mapping system.  See the other tutorials and material for similar discussions on other mechanism by which multi-modal posteriors manifest.\n",
    "- For a longer version of this example, see [open-source solver documentation here](https://juliarobotics.org/Caesar.jl/latest/examples/basic_slamedonut/).\n",
    "\n",
    "Visit [www.NavAbility.io](https://www.NavAbility.io) for more about how to use these and other advanced navigation features in your application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
